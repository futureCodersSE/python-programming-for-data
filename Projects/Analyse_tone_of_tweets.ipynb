{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyse tone of tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsgkRlNd8GAB/wxOZFL2sE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-programming-for-data/blob/main/Projects/Analyse_tone_of_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project - analyse a set of tweets for tone\n",
        "---\n",
        "\n",
        "Search for some tweets (maybe with a particular tag, maybe from a particular user) and analyse the text for its tone, using the IBM Tone Analyser, or another IBM service\n",
        "\n",
        "1.  Sign up for a developer account on Twitter (https://developer.twitter.com/) and copy your bearer token to a document on your own device (e.g. notepad)\n",
        "\n",
        "2.  Install the tweepy library (for Twitter) into this notebook"
      ],
      "metadata": {
        "id": "wvfWi5l5zLmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy --upgrade"
      ],
      "metadata": {
        "id": "wEjMmg7A2-km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. store your bearer token in an environment variable (a variable within the OS) so that it can be hidden from notebook viewers (never upload a visible security code (key or token) to Github.   ONCE you have run the code cell below, remove the output cell that shows the bearer token you have copied in"
      ],
      "metadata": {
        "id": "_4eqWM-N3HgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['BEARER_TOKEN'] = input(\"Bearer token: \")"
      ],
      "metadata": {
        "id": "x7vLXt2VwY_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lNU8LnVadOE"
      },
      "outputs": [],
      "source": [
        "import tweepy as tw\n",
        "\n",
        "# get a Twitter client that will run a search for recent tweets (see https://docs.tweepy.org/en/stable/client.html#tweepy.Client.unhide_reply for other functions available in the client)\n",
        "def get_tweets():\n",
        "    client = tw.Client(bearer_token=os.environ.get('BEARER_TOKEN'))\n",
        "    query = 'from:SmudgePoppy'\n",
        "    tweets = client.search_recent_tweets(query=query, tweet_fields=['context_annotations', 'created_at'], max_results=10)\n",
        "    return tweets\n",
        "\n",
        "# use the get_tweets() function to get a list of tweets\n",
        "tweet_list = get_tweets()\n",
        "for tweet in tweet_list[0]:\n",
        "    tweet = str(tweet)\n",
        "    tweetparts = tweet.split(':')\n",
        "    if len(tweetparts) > 1:\n",
        "      tweet = tweetparts[1]\n",
        "    twt = \" \".join(tweet.splitlines())\n",
        "    print(twt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggestions\n",
        "---\n",
        "\n",
        "Collect a set of tweets with a common thread (same user, same topic, mentions the same account).   \n",
        "\n",
        "If you have an IBM Cloud (Lite) account and can access the Tone Analyser, analyse the tweets in relation to tone/sentiment.\n",
        "\n",
        "If not, you could analyse in a different way.  There is a python library called [NLTK](https://www.nltk.org/) which has some useful functions for tagging text with tokens (grammatical identification - [ref](https://www.nltk.org/book/ch05.html) ).\n",
        "\n",
        "To use - `!pip install nltk` (just once), then give the word_tokenize function a try.  You could create a bar chart to show the distribution of different tags."
      ],
      "metadata": {
        "id": "c8OLpaIi4G7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9H6D7m-m4pV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}