{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-programming-for-data/blob/main/Worksheets/4_Wrangle_the_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKBQIxC4YPKX"
      },
      "source": [
        "# Merging dataframes, creating new columns, replacing with default or correctly formatted values\n",
        "---\n",
        "\n",
        "## Merging dataframes\n",
        "\n",
        "We often want to use data from a set of different data files, or a set of dataframes we have prepared, to combine into one dataframe.\n",
        "\n",
        "### To merge two dataframes together when both dataframes have column headings in common - stacking them one on top of another \n",
        "\n",
        "If `df1` and `df2` have some column headings in common, to combine the two into one dataframe we use:  \n",
        "\n",
        "`pd.concat([dataframes to combine])`\n",
        "\n",
        "This will create a new dataframe with all columns from the original two dataframes, which we can store in a new variable for later use.  Missing values are filled with null values. \n",
        "\n",
        "If we want only the column headings that appear in both tables, we can use join='inner':\n",
        "\n",
        "`pd.concat([dataframes to combine], join='inner')` \n",
        "\n",
        "We may also need to refactor the indexing, where two tables are indexed from 0 upwards, adding the two tables together will result in multiple occurences of the same index.  This can be overcome by using ignore_index=True:\n",
        "\n",
        "`pd.concat([dataframes to combine], join='inner', ignore_index=True)`\n",
        "\n",
        "\n",
        "### Merging dataframes by common column matching values\n",
        "\n",
        " `pd.merge(dataframe1, dataframe2)`\n",
        "\n",
        " extra parameters: \n",
        " * which columns to merge by when the column name is the same in both dataframes: \n",
        "  * single column `pd.merge(df, df2, on='column_name')`  \n",
        "  * multiple columns `pd.merge(df, df2, on=['column1', 'column2']`\n",
        "\n",
        "* which columns to merge by when columns have different names in each dataframe \n",
        "  * single column `pd.merge(df1, df2, left_on = 'df1_column', right_on = 'df2_column')`\n",
        "  * multiple column `pd.merge(df1, df2, left_on = ['df1_column1', 'df1_column2'], right_on = ['df2_column1', 'df2_column2'])`\n",
        "* what kind of join (inner, left, right or cross) inner is default\n",
        "  * `pd.merge(df1, df2, how = '....')`\n",
        "  * inner will join with all columns\n",
        "  * left joins with just first stated df columns \n",
        "  * right joins with just second stated df columns\n",
        "  * cross is a mix of both\n",
        "\n",
        "\n",
        "\n",
        "### Difference between concat and merge: \n",
        "\n",
        "```\n",
        "df1:  \n",
        "          Key  data1\n",
        "      0   b   0\n",
        "      1   b   1\n",
        "      2   a   2\n",
        "      3   c   3\n",
        "      4   a   4\n",
        "      5   a   5\n",
        "      6   b   6\n",
        "\n",
        "df2:\n",
        "    Key data2\n",
        "0   a   0\n",
        "1   b   1\n",
        "2   d   2\n",
        "\n",
        "# merge would look like this:\n",
        "\n",
        "pd.merge(df1, df2)\n",
        "\n",
        "   Key data1 data2\n",
        "0   b    0    1\n",
        "1   b    1    1\n",
        "2   b    6    1\n",
        "3   a    2    0\n",
        "4   a    4    0\n",
        "5   a    5    0\n",
        "\n",
        "# concat would look like this\n",
        "\n",
        "pd.concat([df1, df2])\n",
        "\n",
        "   Key data1 data2\n",
        "0   b   0     NaN\n",
        "1   b   1     NaN\n",
        "2   a   2     NaN\n",
        "3   c   3     NaN\n",
        "4   a   4     NaN\n",
        "5   a   5     NaN\n",
        "6   b   6     NaN\n",
        "0   a   Nan   0\n",
        "1   b   Nan   1\n",
        "2   d   Nan   2\n",
        "```\n",
        "\n",
        "Merge is particularly useful with datasets that share a unique index eg. two datasets that were indexed by date or country \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0mUEA5ugGyJ"
      },
      "source": [
        "### Exercise 1 - combine the two data sets\n",
        "\n",
        "The Excel file at this URL https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true contains TWO data sheets named county-level and state-level.  \n",
        "\n",
        "Read the county-level sheet into a dataframe called **county_level_df** \n",
        "Read the state-level sheet into a dataframe called **state_level_df** \n",
        "\n",
        "Write a function called **combine_whole** which: \n",
        "\n",
        "Uses `pd.concat([list of dataframes])` to combine the two dataframes into a new dataframe called **income_df**, filling missing values with null values.  \n",
        "\n",
        "**Important**\n",
        "Spend some time displaying `county_level_df`, `state_level_df` and the combined df so that you can see what is happening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6qHNDn-YN0i"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "county_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name='county-level')\n",
        "state_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name='state-level')\n",
        "\n",
        "def combine_whole():\n",
        "  # add code to combine the 2 dataframes, filling missing values with NA\n",
        "\n",
        "\n",
        "  return new_df\n",
        "\n",
        "\n",
        "# create new dataframe from your function above \n",
        "income_df = combine_whole()\n",
        "\n",
        "# This will run and test your code to check your new dataframe contains null values \n",
        "actual = income_df.isnull().values.any()\n",
        "expected = True \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aekH_ewx7FM3"
      },
      "source": [
        "### Exercise 2 - ignoring index to get a new indexing system\n",
        "---\n",
        "\n",
        "All rows in each dataframe are indexed from 0 to one less than the number of rows.  You may have noticed that the concatenation in the previous exercise has kept the indexing from the individual tables, so there are two rows labelled 0 and two labelled 1, etc.  \n",
        "\n",
        "If we are making a new table it may make sense to create a new set of indices, from 0 to one less than the length of the new table.   Do this by adding an extra paramater `ignore_index=True`.  ignore_index is False by default and all original indices are kept.\n",
        "\n",
        "We can also use `join='inner'` to only join columns which are common to both tables\n",
        "\n",
        "Write a function called **combine_common** which will: \n",
        "\n",
        "Combine the dataframes `county_level_df` and `state_level_df` into a new dataframe called `income_df`, adding the parameter `ignore_index=True` and joining via inner join. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ABjwed8Rpo"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "county_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name='county-level')\n",
        "state_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name='state-level')\n",
        "\n",
        "def combine_common():\n",
        "  # add code to combine the 2 dataframes ignoring index and using inner join\n",
        "\n",
        "\n",
        "  return new_df\n",
        "\n",
        "# create new dataframe from your function above \n",
        "income_df = combine_common()\n",
        "\n",
        "\n",
        "# This will run and test your code to check your new dataframe ends with the correct index and has the right number of columns \n",
        "actual = income_df.index[-1]\n",
        "expected = 22\n",
        "\n",
        "if actual == expected and len(income_df.columns) == 3:\n",
        "  print(\"Test passed\", actual, len(income_df.columns))\n",
        "else:\n",
        "  print(\"Test failed, expected last row index of\", expected, \"got\", actual, \"and expected 3 columns but got\", len(income_df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAJS3TJCz_p"
      },
      "source": [
        "# Appending rows to a dataframe\n",
        "\n",
        "Where two dataframes have matching columns, we can append one to the other to add the records from one onto the end of the other.\n",
        "\n",
        "We do this using dataframe.append()\n",
        "\n",
        "`income_2 = income.append()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwarv13blWyg"
      },
      "source": [
        "### Exercise 3 - add new rows to the end of the income dataframe\n",
        "\n",
        "The sheet `income` in the Excel data file has 10 further records showing State, Age and Income only, so this table matches the income dataframe exactly.\n",
        "\n",
        "Read the data from sheet_name `income` in the same Excel data file into a new dataframe called **income_new**.  \n",
        " \n",
        "Write a function called **combine_income** which will: \n",
        "\n",
        "Append this dataframe to the `income_df` dataframe to form a new dataframe called **income_df_v2**.  Use the ignore_index=True parameter to reindex.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exik-fYQ_ORy"
      },
      "source": [
        "import pandas as pd\n",
        "income_new = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name='income')\n",
        "\n",
        "def combine_income():\n",
        "  # add code below to join the income_new dataframe with the income_df dataframe ignoring the index\n",
        "\n",
        "\n",
        "  return income_df_v2\n",
        "\n",
        "# save returned dataframe in a variable\n",
        "income_df_v2 = combine_income()\n",
        "\n",
        "# This will run and test your code to see if new dataframe has correct number of columns and correct indexing \n",
        "actual = income_df_v2.index[-1]\n",
        "expected = 32\n",
        "\n",
        "if actual == expected and len(income_df_v2.columns) == 4:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected last row index of\", expected, \"got\", actual, \"and expected 3 columns but got\", len(income_df_v2.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6W6V8P9Eo2A"
      },
      "source": [
        "### Exercise 4 - Create a new Pop column in county_level_df\n",
        "\n",
        "Looking at the tables country_level_df and state_level_df, each has a column containing data on population.  One column is headed *Population* and the other is headed *Pop*.  Ideally these would be merged into one column and this would minimise the number of NaN entries.  \n",
        "\n",
        "Write a function called **create_pop** that:\n",
        "\n",
        "*  Add a new column called '`Pop`' to the `county_level_df` dataframe which contains a copy of all the values in the '`Population`' column  (`df['new_name'] = df['existing_name']`)  \n",
        "*  Drop the 'Population' column `df.drop([column name], axis=1)` from `county_level_df` and store the result in a new dataframe called **county_level_df_v2**\n",
        "\n",
        "**What does `axis=1` mean?** \n",
        "For a number of processes, we need to tell the function whether we want it to work on columns or rows.  Use `axis=0`for rows and `axis=1` for columns.  In most cases, the function will already know what it needs to work on, or will make an assumption.  `df.drop()` assumes that you want to drop a row, unless you tell it you want to drop columns instead.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb_FWSLbG_zo"
      },
      "source": [
        "import pandas as pd\n",
        "county_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name = 'county-level')\n",
        "\n",
        "def create_pop():\n",
        "  # add code below to add 'Pop' column \n",
        "\n",
        "\n",
        "  return county_level_df_v2\n",
        "\n",
        "\n",
        "# save returned dataframe in a variable\n",
        "actual = create_pop()\n",
        "\n",
        "# This will run and test your code to see if new dataframe contains pop column and dropped population column \n",
        "if 'Pop' in actual.columns and len(actual.columns) == 5:\n",
        "  print(\"Test passed, contains 5 columns including Pop column\")\n",
        "elif 'Pop' in actual.columns and len(actual.columns) != 5:\n",
        "  print(\"Test not passed, expected 5 columns, instead got\", len(actual.columns))\n",
        "else: \n",
        "  print(\"Test not passed, column Pop not present\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ku407dEU_3"
      },
      "source": [
        "## Exercise 5 - clean up the format of the Pop column in state_level_df\n",
        "\n",
        "Now that both dataframes have a Pop column, we should make the data consisent in format for both dataframes.\n",
        "\n",
        "In `state_level_df` the values in the `Pop` column are in 1000s.  In `county_level_df_v2` the values in the `Pop` column are actual numbers.  Let's convert the `state_level_df` values from 1000s for consistency.  We can do this by performing an operation on a column (e.g. `df[column name] = df[column name] * 100`) \n",
        "\n",
        "**Something to think about**  \n",
        "When making changes to a dataframe, it is often useful to be working on a copy rather than the original.  You can do this using the `dataframe.copy()` function.  In the example below a new dataframe, which is a copy of the `state_level_df` dataframe, has been created and stored in the new variable **state_level_df_copy**\n",
        "\n",
        "**Write** a function called **clean_pop** which will:  \n",
        "\n",
        "*  convert the values in the `Pop` column of the dataframe from actual numbers to numbers of 1000s, rounding to whole numbers  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5xM8g68N-wY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "state_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name = 'state-level')\n",
        "county_level_df = pd.read_excel(\"https://github.com/futureCodersSE/python-programming-for-data/blob/main/Datasets/Income-Data.xlsx?raw=true\", sheet_name = 'county-level')\n",
        "state_level_df_copy = state_level_df.copy()\n",
        "\n",
        "def clean_pop():\n",
        "  #add code below which converts the 'Pop' column to a number of 1000s rather than actual numbers \n",
        "\n",
        "\n",
        "  return state_level_df_v2\n",
        "  \n",
        "\n",
        "# create new variable \n",
        "state_level_df_v2 = clean_pop()\n",
        "\n",
        "# This will run and test your code to see if you've correctly converted the column to 10s instead of 1000s\n",
        "actual = state_level_df_v2['Pop'].max()\n",
        "expected = 29\n",
        "\n",
        "if actual == expected and len(state_level_df_v2.columns) == 5:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected max of\", expected, \"got\", actual)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRoghwoOilff"
      },
      "source": [
        "### Exercise 6 - combine the two v2 dataframes using concat\n",
        "\n",
        "Write function **combine_v2** which will: \n",
        "\n",
        "Combine the v2 version of `county_level_df` created by the function `create_pop()` and the v2 version of `state_level_df` created by the function `clean_pop()`.\n",
        "\n",
        " to create a new dataframe called **income_df_v3**.  The join type should be 'inner' and ignore_index should be True\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbSGRddLJXO3"
      },
      "source": [
        "county_level_df_v2 = create_pop()\n",
        "state_level_df_v2 = clean_pop()\n",
        "\n",
        "def combine_v2():\n",
        "  # return the 2 dataframes combined joined inner and ignoring index \n",
        "\n",
        "\n",
        "  return combined_df\n",
        "\n",
        "# This will run and test your code to see if your new dataframe is correct length and has correct number of columns \n",
        "income_df_v3 = combine_v2()\n",
        "\n",
        "actual = len(income_df_v3)\n",
        "actual2 = len(income_df_v3.columns)\n",
        "expected = 23 \n",
        "expected2 = 4 \n",
        "\n",
        "if actual == expected and actual2 == expected2:\n",
        "  print(\"Test passed\", actual, \"rows and 4 columns\")\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"rows\", expected2, \"columns but got\", actual, \"rows and\", actual2,\"columns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXvA-Va2d3QM"
      },
      "source": [
        "### Exercise 7 - Combining dataframes using merge \n",
        "---\n",
        "Read in 2 new dataframes called **skill_df** and **industry_df** using the 'Skill Migration' sheet and 'Industry Migration' sheet from the following Excel spreadsheet:\n",
        "\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "**Write** a function called `get_combine()` which will use the `merge()` function to combine the skill and industry migration dataframes. The two dataframes have different column names for the same data (in `skill_df` there is `skill_group_name`, in `industry_df` it is called `industry_name`.\n",
        "\n",
        "Use the following information:  \n",
        "\n",
        "* the merge will combine the `skill_df` and `industry_df` dataframes, including the columns `country_name`, `wb_income` and `net_per_10K_2019` from each, the `skill_group_name` from `skill_df` and `industry_name` from `industry_df`\n",
        "\n",
        "* it will merge  on the columns: `country_name` and `skill_group_name` from the **left** dataframe(`skill_df`)\n",
        "\n",
        "* it will merge on the columns: `country_name` and `industry_name` from the **right** dataframe(`industry_df`) _Remember: in `industry_df` the column that corresponds to `skill_group_name` is called `industry_name`_\n",
        "\n",
        "* display the merged dataframe's `.info()` so that you can see what columns have been made in the merge\n",
        "* return the new dataframe, which should contain the 3 merged columns, two `wb_income` columns and the two 'net_per_10k_2019' columns (total 7). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC2b4eBhi3-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "7425a46f-a902-4836-bc5d-c81505eced67"
      },
      "source": [
        "import pandas as pd\n",
        "# read new dataframes skill_df and industry_df\n",
        "skill_df = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\", sheet_name=\"Skill Migration\")\n",
        "industry_df = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\", sheet_name=\"Industry Migration\")\n",
        "\n",
        "\n",
        "def get_combine():\n",
        "  # merge dataframes into variable called migration_df and return it \n",
        "\n",
        "\n",
        "  return migration_df\n",
        "\n",
        "# This will run and test your code to see if your new dataframe is correct length and has correct number of columns \n",
        "merged = get_combine()\n",
        "actual = merged.shape[0]\n",
        "actual2 = merged.shape[1]\n",
        "expected = 873 \n",
        "expected2 = 7\n",
        "\n",
        "if actual == expected and actual2 == expected2:\n",
        "  print(\"Test passed\", actual, \"rows\", actual2, \"columns\")\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"rows\", expected2, \"columns but got\", actual, \"rows and\", actual2,\"columns\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d68d7b057aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This will run and test your code to see if your new dataframe is correct length and has correct number of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mactual2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5d68d7b057aa>\u001b[0m in \u001b[0;36mget_combine\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmigration_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This will run and test your code to see if your new dataframe is correct length and has correct number of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'migration_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZOHWyPOHkmy"
      },
      "source": [
        "### Exercise 8 - pivot table of state and population \n",
        "---\n",
        "\n",
        "Write a function called **create_pivot** which will:\n",
        "\n",
        "Create a pivot table of `Pop` by `State` and store the result in a new dataframe called **population_pivot**  using `income_df_v3` created in exercise 6\n",
        "\n",
        "To make a pivot table:\n",
        "\n",
        "`df_pivot = pd.pivot_table(\n",
        "      df, \n",
        "      values = 'column1 name',\n",
        "      index = 'column2 name', \n",
        "      columns = 'column3 name',\n",
        "      aggfunc = np.mean\n",
        ")` \n",
        " \n",
        "If index column is not specified, it will automatically use the existing dataframe index   \n",
        "\n",
        "**Note**:  np.mean is a way of calculating the mean in a very efficient way using a library called `numpy` (which is a later part of the course). `numpy` has been imported in the code already.\n",
        "\n",
        "**Test Input**  \n",
        "population_pivot.shape   \n",
        "**Test Output**  \n",
        "(1, 5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZC9EuabJIGi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_pivot(df):\n",
        "  #add code below which creates a pivot table of Pop and State \n",
        "\n",
        "\n",
        "  return df_pivot\n",
        "\n",
        "\n",
        "#save series in a new variable\n",
        "population_pivot = create_pivot(income_df_v3)\n",
        "\n",
        "\n",
        "# This will run and test your code to see if your new series is the correct length\n",
        "actual = len(population_pivot)\n",
        "expected = 5 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "Your answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "Your answer: "
      ]
    }
  ]
}