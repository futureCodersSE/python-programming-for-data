{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Data_retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-programming-for-data/blob/main/1_Data_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "socyySfaK8_B"
      },
      "source": [
        "# Data retrieval\n",
        "---\n",
        "\n",
        "Examples of data being retrieved from a range of sources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_ewU932LIO-"
      },
      "source": [
        "## From a web page\n",
        "---\n",
        "\n",
        "The code below reads all the data tables from the Wikipedia page on Glasgow.  The 8th table on the page shows population data over a period of centuries.\n",
        "\n",
        "The code reads the data from the page into a list of datatables.  The index [7] is used to access the 8th table in the list.  Change the index to see other data tables.  Use len(datatables) to find out how many tables are in the list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAV9q4J3t-zy"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_data():\n",
        "  datatables = pd.read_html('https://en.wikipedia.org/wiki/Glasgow#Climate')\n",
        "  #  change the line below to look at other tables, add the line print(len(datatables)) to see how many tables there are\n",
        "  df = datatables[7]  #Glasgow population data\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "# run and test the get_data() function, test visually - does it match the data on the web page\n",
        "get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBzjrbk8evK7"
      },
      "source": [
        "## From a local file\n",
        "---\n",
        "\n",
        "You can upload from a local file using the code below.  uploaded = file.upload() will open a file chooser and you can choose the data file from there.  After that, just use the file name to read from it.  \n",
        "\n",
        "The file exists while the notebook is running, so should only be uploaded once.  If you need to access again, cancel the upload.\n",
        "\n",
        "For this exercise you will need a copy of an Excel file.  To get a copy of this file \"public_use-talent-migration.xlsx\" go to this page: https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx and click on the Download button.  You will now have a copy in your Downloads folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w29Lrv_je0nj"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "def get_data():\n",
        "  # upload a set of chosen files then read a specified file\n",
        "  uploaded = files.upload()\n",
        "  df = pd.read_excel(uploaded['public_use-talent-migration.xlsx'],sheet_name=\"Industry Migration\")\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "# run and test the get_data() function, test visually - does it match the data on the web page\n",
        "get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9m4HHb3Loxe"
      },
      "source": [
        "## From a csv file hosted on Github.com\n",
        "---\n",
        "\n",
        "The code below reads the data table stored in a Comma Separated Values file (this is a text file containing rows of data with each column within the row separated from the next column by a comma).  \n",
        "\n",
        "If you were using Jupyter Notebooks on your device, the url could be replaced with the path to the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mVk6FwZ-XZu"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/Paisley-Weather-Data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVBfyjCQMVvA"
      },
      "source": [
        "## From an Excel file hosted on Github.com\n",
        "---\n",
        "\n",
        "The code below reads the data table from a sheet in an Excel file.  If you don't specify a sheet then it will assume that you want to read the data from the first sheet in the Excel workbook (sheet_name = 0).  If you don't know the sheet name but know it is the second sheet, you can use sheet_name = 1, or 2 for the third sheet, etc.\n",
        "\n",
        "If you were using Jupyter Notebooks on your device, the url could be replace with the path to the Excel file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Att2-4UtBAhW"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "df = pd.read_excel(url,sheet_name=\"Industry Migration\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NQA3HFJOT8X"
      },
      "source": [
        "## From an API which delivers the data in JSON format\n",
        "---\n",
        "\n",
        "The code below requests the data from the url.  This is a bit more tricky than the other ways to get the data as how you access the data will depend on how it is organised.\n",
        "\n",
        "In this example, the data is returned as a dictionary, which will have the key 'data' against which the actual data is stored.  In the example, the data has been taken from the 'data' key/value pair and is stored in json_data. \n",
        "\n",
        "Again, in this example, the json_data is a list of json_objects but it only has one object in the list.  Try adding the line `print(json_data)` to see this.  \n",
        "\n",
        "data_table is the first object in the json_data list.  Try adding the line `print(data_table)` to see this.\n",
        "\n",
        "In this example, the data table object has three keys, 'to', 'from' and 'regions'.  The 'regions' value is the data we want to use in our dataframe, so we normalize this json data into a pandas dataframe (df), which you can see as the output.  \n",
        "\n",
        "Each API is likely to deliver its data in a different format and so you will need to be happy to read the documentation and to inspect the data to see what keys and indexes you need to access.\n",
        "\n",
        "For information on the format of the data, see https://carbon-intensity.github.io/api-definitions/#regional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uEDgTjJFYiZ"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "url = \"https://api.carbonintensity.org.uk/regional\"\n",
        "json_data = requests.get(url).json()['data']\n",
        "data_table = json_data[0]\n",
        "df = pd.json_normalize(data_table['regions'])\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ow6HQWqIsh0"
      },
      "source": [
        "### Exercise - upload a file from your local drive\n",
        "\n",
        "Visit the Kent and Medway Air Quality site: https://kentair.org.uk/\n",
        "\n",
        "Collect a data file containing data on Ozone levels in Dover:\n",
        "\n",
        "Open the site\n",
        "Go to the Data page  \n",
        "Launch the data selector tool  \n",
        "Select:\n",
        "*  Automatic monitoring data\n",
        "*  Measurement data and simple statistics\n",
        "*  Ozone\n",
        "*  Daily mean\n",
        "*  This month\n",
        "*  Thurrock\n",
        "*  Thurrock\n",
        "\n",
        "Click on Download CSV\n",
        "\n",
        "This should be downloaded into your Downloads folder.\n",
        "\n",
        "NOW\n",
        "\n",
        "Write a function that will allow you to upload the file and then read its contents into a dataframe.\n",
        "\n",
        "To read an uploaded CSV file (which will be in bytes format) use:\n",
        "\n",
        "```\n",
        "df = pd.read_csv(io.BytesIO(uploaded['your filename']))\n",
        "```\n",
        "\n",
        "\n",
        "Display the dataframe and compare the contents with the output on the site you took the data from.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxCrBhaWKsku"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "def get_data():\n",
        "  # upload a set of chosen files then read a specified file\n",
        "  !rm NO2-daily-mean-2014-2021-Swale-Newington.csv\n",
        "  uploaded = files.upload()\n",
        "  df = pd.read_csv(io.BytesIO(uploaded['NO2-daily-mean-2014-2021-Swale-Newington.csv']))\n",
        "  return df\n",
        "\n",
        "get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACTIVITIES\n",
        "\n",
        "RUN ALL THE CODE CELLS ABOVE TO SEE WHAT THEY DO AND WHAT DATA THEY GET FOR YOU.\n",
        "\n",
        "Now have a go at opening a few data sets yourself.\n",
        "\n",
        "### Exercise 1\n",
        "---\n",
        "\n",
        "*  Open the datasets list: [here](https://docs.google.com/document/d/1cijDOCDixsYu-Rr9pC8STPPXado3xoFpgBAZgdDTLHs/edit?usp=sharing)  \n",
        "\n",
        "*  Find a dataset that is a CSV file, copy the code above (for online CSV) into the code cell below\n",
        "\n",
        "*  Run the code to open the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tm1GBCJMXOXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sRoQo_rKZEJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2\n",
        "---\n",
        "Open the datasets list: [here](https://docs.google.com/document/d/1cijDOCDixsYu-Rr9pC8STPPXado3xoFpgBAZgdDTLHs/edit?usp=sharing)  \n",
        "\n",
        "* Find a dataset that is an Excel file\n",
        "* Copy the code above (for Excel files on Github) into the code cell below\n",
        "* Change the line\n",
        "```\n",
        "df = pd.read_excel(url,sheet_name=\"Industry Migration\") \n",
        "```\n",
        "to \n",
        "```\n",
        "df = pd.read_excel(url)\n",
        "```\n",
        "This will then open the first sheet in the Excel file, rather than a named sheet.\n",
        "\n",
        "* Run the code to open the data."
      ],
      "metadata": {
        "id": "iL8MgXxSZEuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SgPuXv4caFbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3\n",
        "---\n",
        "*  Copy the code from the API delivered in JSON format\n",
        "*  Change the URL to add /england to the end of it\n",
        "*  Run the code to see the data for England only\n",
        "*  Change it again to show data for Scotland, (/scotland)\n",
        "*  Change it again to show data for Wales"
      ],
      "metadata": {
        "id": "kn-okYP4aqo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IT-OLNOgbL0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}